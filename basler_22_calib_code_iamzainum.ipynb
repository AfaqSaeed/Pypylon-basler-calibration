{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration, Rectification, and Keypoints Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_R = \"./captured/both/right/\" #L\n",
    "path_L = \"./captured/both/left/\" #R\n",
    "\n",
    "calib_params = \"./captured/calibrators/calibParams/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the images and saving them into respective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 61\n",
      "['0_L_.png', '1_L_.png', '2_L_.png', '3_L_.png', '4_L_.png', '5_L_.png', '6_L_.png', '7_L_.png', '8_L_.png', '9_L_.png', '10_L_.png', '11_L_.png', '12_L_.png', '13_L_.png', '14_L_.png', '15_L_.png', '16_L_.png', '17_L_.png', '18_L_.png', '19_L_.png', '20_L_.png', '21_L_.png', '22_L_.png', '23_L_.png', '24_L_.png', '25_L_.png', '26_L_.png', '27_L_.png', '28_L_.png', '29_L_.png', '30_L_.png', '31_L_.png', '32_L_.png', '33_L_.png', '34_L_.png', '35_L_.png', '36_L_.png', '37_L_.png', '38_L_.png', '39_L_.png', '40_L_.png', '41_L_.png', '42_L_.png', '43_L_.png', '44_L_.png', '45_L_.png', '46_L_.png', '47_L_.png', '48_L_.png', '49_L_.png', '50_L_.png', '51_L_.png', '52_L_.png', '53_L_.png', '54_L_.png', '55_L_.png', '56_L_.png', '57_L_.png', '58_L_.png', '59_L_.png', '60_L_.png']\n",
      "\n",
      "['0_R_.png', '1_R_.png', '2_R_.png', '3_R_.png', '4_R_.png', '5_R_.png', '6_R_.png', '7_R_.png', '8_R_.png', '9_R_.png', '10_R_.png', '11_R_.png', '12_R_.png', '13_R_.png', '14_R_.png', '15_R_.png', '16_R_.png', '17_R_.png', '18_R_.png', '19_R_.png', '20_R_.png', '21_R_.png', '22_R_.png', '23_R_.png', '24_R_.png', '25_R_.png', '26_R_.png', '27_R_.png', '28_R_.png', '29_R_.png', '30_R_.png', '31_R_.png', '32_R_.png', '33_R_.png', '34_R_.png', '35_R_.png', '36_R_.png', '37_R_.png', '38_R_.png', '39_R_.png', '40_R_.png', '41_R_.png', '42_R_.png', '43_R_.png', '44_R_.png', '45_R_.png', '46_R_.png', '47_R_.png', '48_R_.png', '49_R_.png', '50_R_.png', '51_R_.png', '52_R_.png', '53_R_.png', '54_R_.png', '55_R_.png', '56_R_.png', '57_R_.png', '58_R_.png', '59_R_.png', '60_R_.png']\n"
     ]
    }
   ],
   "source": [
    "'''READING IMAGES FROM FILE AND SORTING THEM'''\n",
    "# listings_L = os.listdir(path_L)\n",
    "# size_L = size(listings_L)\n",
    "# listings_R = os.listdir(path_R)\n",
    "# size_R = size(listings_R)\n",
    "\n",
    "size_L = size(os.listdir(path_L))\n",
    "size_R = size(os.listdir(path_R))\n",
    "\n",
    "number_of_images = 0\n",
    "if size_L == size_R:\n",
    "    number_of_images = size_L\n",
    "#endif\n",
    "\n",
    "offset = 0\n",
    "listings_L, listings_R = [], []\n",
    "for i in range(offset+0, offset+number_of_images):\n",
    "    listings_L.append(f'{i}_L_.png')\n",
    "    listings_R.append(f'{i}_R_.png')\n",
    "#endfor\n",
    "\n",
    "print(size_L,size_R)\n",
    "print(listings_L)\n",
    "print()\n",
    "print(listings_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 61\n"
     ]
    }
   ],
   "source": [
    "imgL_list = []\n",
    "imgR_list = []\n",
    "\n",
    "i = 0\n",
    "while(i<size_L):\n",
    "    imL = cv2.imread(path_L+listings_L[i], 0)\n",
    "    imgL_list.append(imL)\n",
    "    i+=1\n",
    "#endwhile\n",
    "\n",
    "i = 0\n",
    "while(i<size_R):\n",
    "    imR = cv2.imread(path_R+listings_R[i], 0)\n",
    "    imgR_list.append(imR)\n",
    "    i+=1\n",
    "#endwhile\n",
    "\n",
    "import random\n",
    "temp = list(zip(imgL_list, imgR_list))\n",
    "random.shuffle(temp)\n",
    "imgL_list, imgR_list = zip(*temp)\n",
    "print(len(imgR_list), len(imgL_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230, 228, 235, ...,  10,  15,   9],\n",
       "       [236, 234, 239, ...,  11,  12,  13],\n",
       "       [228, 237, 234, ...,  14,  13,  12],\n",
       "       ...,\n",
       "       [ 69,  80,  63, ...,  29,  29,  27],\n",
       "       [ 72,  66,  74, ...,  18,  23,  33],\n",
       "       [ 76,  66,  69, ...,  18,  35,  21]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgR_list[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of chessboard points\n",
    "Reference -> https://stackoverflow.com/questions/37310210/camera-calibration-with-opencv-how-to-adjust-chessboard-square-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.    0.    0. ]\n",
      " [ 24.5   0.    0. ]\n",
      " [ 49.    0.    0. ]\n",
      " [ 73.5   0.    0. ]\n",
      " [ 98.    0.    0. ]\n",
      " [122.5   0.    0. ]\n",
      " [147.    0.    0. ]\n",
      " [171.5   0.    0. ]\n",
      " [196.    0.    0. ]\n",
      " [  0.   24.5   0. ]\n",
      " [ 24.5  24.5   0. ]\n",
      " [ 49.   24.5   0. ]\n",
      " [ 73.5  24.5   0. ]\n",
      " [ 98.   24.5   0. ]\n",
      " [122.5  24.5   0. ]\n",
      " [147.   24.5   0. ]\n",
      " [171.5  24.5   0. ]\n",
      " [196.   24.5   0. ]\n",
      " [  0.   49.    0. ]\n",
      " [ 24.5  49.    0. ]\n",
      " [ 49.   49.    0. ]\n",
      " [ 73.5  49.    0. ]\n",
      " [ 98.   49.    0. ]\n",
      " [122.5  49.    0. ]\n",
      " [147.   49.    0. ]\n",
      " [171.5  49.    0. ]\n",
      " [196.   49.    0. ]\n",
      " [  0.   73.5   0. ]\n",
      " [ 24.5  73.5   0. ]\n",
      " [ 49.   73.5   0. ]\n",
      " [ 73.5  73.5   0. ]\n",
      " [ 98.   73.5   0. ]\n",
      " [122.5  73.5   0. ]\n",
      " [147.   73.5   0. ]\n",
      " [171.5  73.5   0. ]\n",
      " [196.   73.5   0. ]\n",
      " [  0.   98.    0. ]\n",
      " [ 24.5  98.    0. ]\n",
      " [ 49.   98.    0. ]\n",
      " [ 73.5  98.    0. ]\n",
      " [ 98.   98.    0. ]\n",
      " [122.5  98.    0. ]\n",
      " [147.   98.    0. ]\n",
      " [171.5  98.    0. ]\n",
      " [196.   98.    0. ]\n",
      " [  0.  122.5   0. ]\n",
      " [ 24.5 122.5   0. ]\n",
      " [ 49.  122.5   0. ]\n",
      " [ 73.5 122.5   0. ]\n",
      " [ 98.  122.5   0. ]\n",
      " [122.5 122.5   0. ]\n",
      " [147.  122.5   0. ]\n",
      " [171.5 122.5   0. ]\n",
      " [196.  122.5   0. ]]\n"
     ]
    }
   ],
   "source": [
    "'''CALIBRATING STARTS HERE'''\n",
    "img_left_points = []\n",
    "img_right_points = []\n",
    "obj_points = []\n",
    "size = size_L\n",
    "\n",
    "h, w = 9, 6\n",
    "pattern_size = (h,w)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((w*h,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:h,0:w].T.reshape(-1,2)*24.5\n",
    "print(objp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "while(j<size):\n",
    "    print(j)\n",
    "    image_size = imgL_list[j].shape\n",
    "    find_chessboard_flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_FAST_CHECK\n",
    "\n",
    "    left_found, left_corners = cv2.findChessboardCorners(imgL_list[j], pattern_size, flags = find_chessboard_flags)\n",
    "    right_found, right_corners = cv2.findChessboardCorners(imgR_list[j], pattern_size, flags = find_chessboard_flags)\n",
    " \n",
    "    if left_found:\n",
    "        cv2.cornerSubPix(imgL_list[j], left_corners, (11,11), (-1,-1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "    if right_found:\n",
    "        cv2.cornerSubPix(imgR_list[j], right_corners, (11,11), (-1,-1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    " \n",
    "    if left_found and right_found:\n",
    "        img_left_points.append(left_corners)\n",
    "        img_right_points.append(right_corners)\n",
    "        obj_points.append(objp)\n",
    "\n",
    "    #cv2.imshow(\"left\", imgL_list[j])q \n",
    "    cv2.drawChessboardCorners(imgL_list[j], pattern_size, left_corners, left_found)\n",
    "    cv2.drawChessboardCorners(imgR_list[j], pattern_size, right_corners, right_found)\n",
    "    #cv2.waitKey(300)\n",
    "    cv2.imshow(\"r chess\", cv2.resize(imgR_list[j], (640,480)))\n",
    "    cv2.imshow(\"l chess\", cv2.resize(imgL_list[j], (640,480)))\n",
    "    cv2.waitKey(500)\n",
    "    j+=1\n",
    "#endwhile\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_left_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imL.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imL.shape[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the cameras on the basis of chessboard points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras Ready to use\n"
     ]
    }
   ],
   "source": [
    "# Determine the new values for different parameters\n",
    "#   Right Side\n",
    "retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_points,\n",
    "                                                        img_right_points,\n",
    "                                                        imR.shape[::-1],None,None)\n",
    "hR,wR = imR.shape[:2]\n",
    "OmtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,\n",
    "                                                   (wR,hR),1,(wR,hR))\n",
    "\n",
    "#   Left Side\n",
    "retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_points,\n",
    "                                                        img_left_points,\n",
    "                                                        imL.shape[::-1],None,None)\n",
    "hL,wL = imL.shape[:2]\n",
    "OmtxL, roiL = cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))\n",
    "\n",
    "print('Cameras Ready to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reprojection error - right:  1.0766688996804756\n",
      "mean reprojection error - left:  0.8365157029525241\n",
      "roiR:  (353, 170, 907, 843)\n",
      "roiL:  (359, 169, 931, 846)\n"
     ]
    }
   ],
   "source": [
    "print('mean reprojection error - right: ', retR)\n",
    "print('mean reprojection error - left: ', retL)\n",
    "\n",
    "print(\"roiR: \", roiR)\n",
    "print(\"roiL: \", roiL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imR.copy()\n",
    "# using cv2.undistort\n",
    "dst = cv2.undistort(img, mtxR, distR, None, OmtxR)\n",
    "x,y,w,h = roiR\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "# using remapping\n",
    "right_map = cv2.initUndistortRectifyMap(mtxR, distR, None, OmtxR, img.shape[::-1], cv2.CV_16SC2)\n",
    "rdst = cv2.remap(img,right_map[0],right_map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "x,y,w,h = roiR\n",
    "rdst = rdst[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('undist', cv2.resize(dst, (640,480)))\n",
    "cv2.imshow('rundist', cv2.resize(rdst, (640,480)))\n",
    "cv2.imshow('img', cv2.resize(img, (640,480)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#cv2.imwrite('./undist.png', dst)\n",
    "#cv2.imwrite('./rundist.png', rdst)\n",
    "#cv2.imwrite('./img.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 170, 907, 843)\n",
      "(359, 169, 931, 846)\n"
     ]
    }
   ],
   "source": [
    "print(roiR)\n",
    "print(roiL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " format -> \n",
      " [['fx', '0', 'cx'], ['0', 'fy', 'cy'], ['0', '0', '1']]\n",
      "\n",
      " mtxR -> \n",
      " [[868.37201109   0.         810.36308916]\n",
      " [  0.         862.78306168 594.25535866]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " OmtxR -> \n",
      " [[492.20748901   0.         811.87689625]\n",
      " [  0.         606.27728271 587.55357665]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " mtxL -> \n",
      " [[880.07697126   0.         803.24183072]\n",
      " [  0.         880.18729834 596.5114081 ]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " OmtxL -> \n",
      " [[512.04510498   0.         826.11342001]\n",
      " [  0.         620.84625244 589.85326051]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "formatm = [[\"fx\",\"0\",\"cx\"],[\"0\",\"fy\",\"cy\"],[\"0\",\"0\",\"1\"]]\n",
    "print('\\n format -> \\n',formatm)\n",
    "print('\\n mtxR -> \\n',mtxR,2*'\\n','OmtxR -> \\n',OmtxR,2*'\\n','mtxL -> \\n',mtxL,2*'\\n','OmtxL -> \\n',OmtxL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "criteria_stereo = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "\n",
    "# StereoCalibrate function\n",
    "# flags = 0\n",
    "# flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# flags |= cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "# flags |= cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "# flags |= cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "# flags |= cv2.CALIB_FIX_ASPECT_RATIO\n",
    "# flags |= cv2.CALIB_ZERO_TANGENT_DIST\n",
    "# flags |= cv2.CALIB_RATIONAL_MODEL\n",
    "# flags |= cv2.CALIB_SAME_FOCAL_LENGTH\n",
    "# flags |= cv2.CALIB_FIX_K3\n",
    "# flags |= cv2.CALIB_FIX_K4\n",
    "# flags |= cv2.CALIB_FIX_K5\n",
    "flags = cv2.CALIB_FIX_ASPECT_RATIO | cv2.CALIB_ZERO_TANGENT_DIST | cv2.CALIB_SAME_FOCAL_LENGTH | cv2.CALIB_RATIONAL_MODEL | cv2.CALIB_FIX_K3 | cv2.CALIB_FIX_K4 | cv2.CALIB_FIX_K5\n",
    "#flags = cv2.CALIB_FIX_INTRINSIC\n",
    "retS, MLS, dLS, MRS, dRS, R, T, E, F = cv2.stereoCalibrate(obj_points,\n",
    "                                                          img_left_points,\n",
    "                                                          img_right_points,\n",
    "                                                          mtxL,\n",
    "                                                          distL,\n",
    "                                                          mtxR,\n",
    "                                                          distR,\n",
    "                                                          imR.shape[::-1],\n",
    "                                                          criteria_stereo,\n",
    "                                                          flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reprojection error:  1.2968537770583775\n",
      " MRS ->  [[868.37201109   0.         810.36308916]\n",
      " [  0.         862.78306168 594.25535866]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " mtxR ->  [[868.37201109   0.         810.36308916]\n",
      " [  0.         862.78306168 594.25535866]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " MLS ->  [[880.07697126   0.         803.24183072]\n",
      " [  0.         880.18729834 596.5114081 ]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      " mtxL ->  [[880.07697126   0.         803.24183072]\n",
      " [  0.         880.18729834 596.5114081 ]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('mean reprojection error: ', retS)\n",
    "print(' MRS -> ',MRS,2*'\\n','mtxR -> ',mtxR,2*'\\n','MLS -> ',MLS,2*'\\n','mtxL -> ',mtxL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rotational -> \n",
      " [[ 0.99987344  0.00912293 -0.01303375]\n",
      " [-0.00947706  0.9995804  -0.02737168]\n",
      " [ 0.01277857  0.02749174  0.99954035]] \n",
      "\n",
      " Translational -> \n",
      " [[297.85296464]\n",
      " [  1.16534976]\n",
      " [ -7.9825853 ]] \n",
      "\n",
      " Essential -> \n",
      " [[-6.07599091e-02  8.01127329e+00  9.46317338e-01]\n",
      " [-1.17877107e+01 -8.26132000e+00 -2.97612014e+02]\n",
      " [-3.98797179e+00  2.97717354e+02 -8.13754710e+00]] \n",
      "\n",
      " Fundamental -> \n",
      " [[ 9.44979556e-09 -1.24581170e-06  6.06022690e-04]\n",
      " [ 1.84518100e-06  1.29301781e-06  3.87462679e-02]\n",
      " [-5.65570378e-04 -3.99620417e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(' Rotational -> \\n',R,2*'\\n','Translational -> \\n',T,2*'\\n','Essential -> \\n',E,2*'\\n','Fundamental -> \\n',F)\n",
    "# Rotational Translational Essential Fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(calib_params+'R.npy', R)\n",
    "np.save(calib_params+'T.npy', T)\n",
    "np.save(calib_params+'E.npy', E)\n",
    "np.save(calib_params+'F.npy', F)\n",
    "\n",
    "np.save(calib_params+'MLS.npy', MLS)\n",
    "np.save(calib_params+'dLS.npy', dLS)\n",
    "np.save(calib_params+'MRS.npy', MRS)\n",
    "np.save(calib_params+'dRS.npy', dRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectifying params through which captured images can be rectified accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StereoRectify function\n",
    "rectify_scale = 1# if 0 image croped, if 1 image nor croped\n",
    "RL, RR, PL, PR, Q, roiL, roiR = cv2.stereoRectify(MLS, dLS, MRS, dRS,\n",
    "                                                 imR.shape[::-1], R, T,\n",
    "                                                 rectify_scale) # last paramater is alpha, if 0= croped, if 1= not croped\n",
    "# initUndistortRectifyMap function\n",
    "Left_Stereo_Map = cv2.initUndistortRectifyMap(MLS, dLS, RL, PL,\n",
    "                                             imR.shape[::-1], cv2.CV_16SC2)   # cv2.CV_16SC2 this format enables us the programme to work faster\n",
    "Right_Stereo_Map = cv2.initUndistortRectifyMap(MRS, dRS, RR, PR,\n",
    "                                              imR.shape[::-1], cv2.CV_16SC2)\n",
    "#*******************************************\n",
    "#***** Parameters for the StereoVision *****\n",
    "#*******************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(calib_params+'RL.npy', RL)\n",
    "np.save(calib_params+'RR.npy', RR)\n",
    "np.save(calib_params+'PL.npy', PL)\n",
    "np.save(calib_params+'PR.npy', PR)\n",
    "\n",
    "np.save(calib_params+'Q.npy', Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 24, 1592, 1176)\n",
      "(15, 0, 1573, 1146)\n"
     ]
    }
   ],
   "source": [
    "print(roiR)\n",
    "print(roiL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -8.60201920e+02],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        -5.94928680e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.71485180e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -3.35613049e-03,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the images to get them rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_num = '1'\n",
    "rect_path = \"./captured/rectified/\"\n",
    "frameL = cv2.imread(path_L+pic_num+'_L_.png')\n",
    "frameR = cv2.imread(path_R+pic_num+'_R_.png')\n",
    "\n",
    "Left_nice = cv2.remap(frameL,Left_Stereo_Map[0],Left_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)  # Rectify the image using the kalibration parameters founds during the initialisation\n",
    "Right_nice = cv2.remap(frameR,Right_Stereo_Map[0],Right_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img):\n",
    "    y,count = 0,0\n",
    "    while(count<40):\n",
    "        img = cv2.line(img, (0,50+y), (img.shape[1],50+y), (y,count*2,y), 2)\n",
    "        y+=30\n",
    "        count+=1\n",
    "    #endwhile\n",
    "    return cv2.resize(img, (640,480))\n",
    "#enddef\n",
    "\n",
    "chairL = frameL.copy()\n",
    "chairR = frameR.copy()\n",
    "\n",
    "xr,yr,wr,hr = roiR\n",
    "xl,yl,wl,hl = roiL\n",
    "\n",
    "#Right_nice = Right_nice[yl:yl+hr, xr:xr+wr]\n",
    "#Left_nice = Left_nice[yl:yl+hr, xl:xl+wl]\n",
    "\n",
    "right_img_remap_copy = Right_nice.copy()\n",
    "left_img_remap_copy = Left_nice.copy()\n",
    "'''\n",
    "y,count = 0,0\n",
    "while(count<40):\n",
    "    chairR = cv2.line(chairR, (0,50+y), (1280,50+y), (0,count*2,y), 2)\n",
    "    chairL = cv2.line(chairL, (0,50+y), (1280,50+y), (0,count*2,y), 2)\n",
    "    right_img_remap_copy = cv2.line(right_img_remap_copy, (0,50+y), (1280,50+y), (0,count*2,y), 2)\n",
    "    left_img_remap_copy = cv2.line(left_img_remap_copy, (0,50+y), (1280,50+y), (0,count*2,y), 2)\n",
    "    y+=30\n",
    "    count+=1\n",
    "'''   \n",
    "cv2.imshow('R', draw_lines(chairR))\n",
    "cv2.imshow('L', draw_lines(chairL))\n",
    "cv2.imshow('R rect', draw_lines(right_img_remap_copy))\n",
    "cv2.imshow('L rect', draw_lines(left_img_remap_copy))\n",
    "cv2.waitKey(0)\n",
    "\n",
    "origLR = np.concatenate((chairL, chairR), axis=1)\n",
    "cv2.imwrite(rect_path+pic_num+'_orig.png', origLR)\n",
    "rectLR = np.concatenate((left_img_remap_copy, right_img_remap_copy), axis=1)\n",
    "cv2.imwrite(rect_path+pic_num+'_rect.png', rectLR)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map using WLS Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayR = cv2.cvtColor(Right_nice,cv2.COLOR_BGR2GRAY)\n",
    "grayL = cv2.cvtColor(Left_nice,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create StereoSGBM and prepare all parameters\n",
    "window_size = 7\n",
    "min_disp = 1\n",
    "num_disp = (16*16)+1-min_disp\n",
    "left_matcher = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = window_size,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32,\n",
    "    disp12MaxDiff = 5,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2)\n",
    "\n",
    "# Used for the filtered image\n",
    "right_matcher = cv2.ximgproc.createRightMatcher(left_matcher) # Create another stereo for right this time\n",
    "\n",
    "# WLS FILTER Parameters\n",
    "lmbda = 80000\n",
    "sigma = 1.8\n",
    "visual_multiplier = 1.0\n",
    " \n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "dispL = left_matcher.compute(grayL,grayR)\n",
    "dispR = right_matcher.compute(grayR,grayL)\n",
    "dispL = np.int16(dispL)\n",
    "dispR = np.int16(dispR)\n",
    "\n",
    "filteredImg = wls_filter.filter(dispL, grayL, None, dispR)  # important to put \"imgL\" here!!!\n",
    "filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "filteredImg = np.uint8(filteredImg)\n",
    "\n",
    "fil = cv2.resize(filteredImg, (1920,1080))\n",
    "cv2.imshow('filteredImg',fil)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# plt.imshow(cv2.cvtColor(fil, cv2.COLOR_GRAY2RGB))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Left_nice.shape, Right_nice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impixelinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgs = []\n",
    "imgs.append(cv2.cvtColor(frameL, cv2.COLOR_BGR2RGB))\n",
    "imgs.append(cv2.cvtColor(frameR, cv2.COLOR_BGR2RGB))\n",
    "imgs.append(cv2.cvtColor(Left_nice, cv2.COLOR_BGR2RGB))\n",
    "imgs.append(cv2.cvtColor(Right_nice, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "row,col = 2,2\n",
    "f, axarr = plt.subplots(row,col,figsize=(10,10))\n",
    "f.tight_layout()\n",
    "\n",
    "axarr[0,0].imshow(imgs[0]),axarr[0,0].set_title('frameL', color='r', size=15), axarr[0,0].axis('off')\n",
    "axarr[0,1].imshow(imgs[1]),axarr[0,1].set_title('frameR', color='r', size=15), axarr[0,1].axis('off')\n",
    "\n",
    "axarr[1,0].imshow(imgs[2]),axarr[1,0].set_title('rectL', color='r', size=15), axarr[1,0].axis('off')\n",
    "axarr[1,1].imshow(imgs[3]),axarr[1,1].set_title('rectR', color='r', size=15), axarr[1,1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('disparity_con')\n",
    "con = np.zeros((500,500,3), np.uint8)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "numDisp = 1\n",
    "highDisp = 30\n",
    "\n",
    "bS = 1\n",
    "highBS = 127\n",
    "\n",
    "# creating trackbars\n",
    "cv2.createTrackbar('disp', 'disparity_con', numDisp, highDisp, nothing)\n",
    "cv2.createTrackbar('block', 'disparity_con', bS, highBS, nothing)\n",
    "\n",
    "while(True):\n",
    "    # get the trackbar positions and set them to l_h, l_s, l_v respectively\n",
    "    numDisp = cv2.getTrackbarPos('disp', 'disparity_con')\n",
    "    bS = cv2.getTrackbarPos('block', 'disparity_con')\n",
    "    if numDisp == 0:\n",
    "        numDisp = 1\n",
    "    if bS == 0:\n",
    "        bS = 1\n",
    "    #endif\n",
    "    cv2.putText(con, 'Disp: '+str(numDisp*16), (150,40),2,1,(255,255,255),1,0)\n",
    "    cv2.putText(con, 'Block: '+str(2*(bS)+1), (150,70),2,1,(255,255,255),1,0)\n",
    "    \n",
    "    stereo = cv2.StereoSGBM_create(1, 16*numDisp, 2*(bS)+1)\n",
    "    disparity = stereo.compute(Left_nice, Right_nice)\n",
    "    #disparity = ((disparity.astype(np.float32)/ 16)-1)/numDisp\n",
    "    #disparity = stereo.compute(origR, origL).astype(np.float32)\n",
    "\n",
    "    norm_coeff = 255 / disparity.max()\n",
    "    cv2.imshow(\"disparity\", disparity * norm_coeff / 255)\n",
    "    #cv2.imshow('disparity', disparity)\n",
    "    cv2.imshow('disparity_con', con)\n",
    "    \n",
    "    con = np.zeros((500,500,3), np.uint8)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL = Left_nice.copy()\n",
    "imgR = Right_nice.copy()\n",
    "out_image = None\n",
    "\n",
    "# Initiate FAST object with default values\n",
    "fast = cv2.FastFeatureDetector_create() \n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# find and draw the keypoints\n",
    "kpL = sift.detect(imgL, None)\n",
    "img2L = cv2.drawKeypoints(imgL, kpL, out_image, color=(255,0,0))\n",
    "kpR = sift.detect(imgR, None)\n",
    "img2R = cv2.drawKeypoints(imgR, kpR, out_image, color=(255,0,0))\n",
    "\n",
    "#cv2.imshow('kpL', img2L)\n",
    "#cv2.imshow('kpR', img2R)\n",
    "#hor = np.hstack((img2L, img2R))\n",
    "vis = np.concatenate((img2L, img2R), axis=1)\n",
    "#cv2.imshow('mkp', vis)\n",
    "#cv2.imwrite('kp.png', vis)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "print(vis.shape)\n",
    "plt.clf()\n",
    "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point cloud -> *problematic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "#enddef\n",
    "\n",
    "disparity = filteredImg.copy()\n",
    "points = cv2.reprojectImageTo3D(disparity, Q)\n",
    "colors = cv2.cvtColor(Left_nice, cv2.COLOR_BGR2RGB)\n",
    "#colors = left_img_remap\n",
    "mask = disparity > disparity.min()\n",
    "out_points = points[mask]\n",
    "out_colors = colors[mask]\n",
    "\n",
    "#cv2.imshow('left', left_img_remap)\n",
    "#cv2.imshow('right', right_img_remap)\n",
    "cv2.imshow('disparity', disparity)\n",
    "cv2.waitKey(0)\n",
    "out_fn = 'out_new.ply'\n",
    "write_ply('out_new.ply', out_points, out_colors)\n",
    "print('%s saved' % 'out_new.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Basler cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypylon import pylon\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Pypylon get camera by serial number\n",
    "serial_number_1 = '22730679' #right\n",
    "serial_number_2 = '22730681' #left\n",
    "cams = []\n",
    "\n",
    "for i in pylon.TlFactory.GetInstance().EnumerateDevices():\n",
    "    cams.append(i)\n",
    "#next\n",
    "\n",
    "print(cams[0].GetSerialNumber(), cams[1].GetSerialNumber())\n",
    "camera_1 = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateDevice(cams[0]))\n",
    "camera_2 = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateDevice(cams[1]))\n",
    "camera_1.Open()\n",
    "camera_2.Open()\n",
    "\n",
    "# Grabing Continusely (video) with minimal delay\n",
    "camera_1.StartGrabbing(pylon.GrabStrategy_LatestImageOnly) \n",
    "camera_2.StartGrabbing(pylon.GrabStrategy_LatestImageOnly) \n",
    "converter = pylon.ImageFormatConverter()\n",
    "\n",
    "# converting to opencv bgr format\n",
    "converter.OutputPixelFormat = pylon.PixelType_BGR8packed\n",
    "converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned\n",
    "\n",
    "while camera_1.IsGrabbing() and camera_2.IsGrabbing():\n",
    "    grabResult_1 = camera_1.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)\n",
    "    grabResult_2 = camera_2.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)\n",
    "\n",
    "    if grabResult_1.GrabSucceeded() and grabResult_2.GrabSucceeded():\n",
    "        # Access the image data\n",
    "        image_1 = converter.Convert(grabResult_1) #right\n",
    "        image_2 = converter.Convert(grabResult_2) #left\n",
    "\n",
    "        frame1 = image_1.GetArray()\n",
    "        frame2 = image_2.GetArray()\n",
    "\n",
    "        frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        vid_right_nice = cv2.remap(frame1,Right_Stereo_Map[0],Right_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "        vid_left_nice = cv2.remap(frame2,Left_Stereo_Map[0],Left_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "        \n",
    "        chairL = frame1_gray.copy()\n",
    "        chairR = frame2_gray.copy()\n",
    "        vid_right_nice_copy = vid_right_nice.copy()\n",
    "        vid_left_nice_copy = vid_left_nice.copy()\n",
    "\n",
    "        y,count = 0,0\n",
    "        while(count<40):\n",
    "            chairR = cv2.line(chairR, (0,50+y), (1920,50+y), (0,count*2,y), 2)\n",
    "            chairL = cv2.line(chairL, (0,50+y), (1920,50+y), (0,count*2,y), 2)\n",
    "            vid_right_nice_copy = cv2.line(vid_right_nice_copy, (0,50+y), (1920,50+y), (0,count*2,y), 2)\n",
    "            vid_left_nice_copy = cv2.line(vid_left_nice_copy, (0,50+y), (1920,50+y), (0,count*2,y), 2)\n",
    "            y+=30\n",
    "            count+=1\n",
    "        #endwhile\n",
    "\n",
    "        cv2.imshow('right', cv2.resize(chairR, (640,480)))\n",
    "        cv2.imshow('left', cv2.resize(chairL, (640,480)))\n",
    "\n",
    "        cv2.imshow('right_nice', cv2.resize(vid_right_nice_copy, (640,480)))\n",
    "        cv2.imshow('left_nice', cv2.resize(vid_left_nice_copy, (640,480)))\n",
    "\n",
    "        # saving images into the respective folders\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "        #endif\n",
    "    #endif\n",
    "    grabResult_1.Release()\n",
    "    grabResult_2.Release()\n",
    "#endwhile\n",
    "    \n",
    "# Releasing the resource    \n",
    "camera_1.StopGrabbing()\n",
    "camera_2.StopGrabbing()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ce69d1d7c485cee53394ee32f6368c7aece10678cce8ee945839465c9a21324"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dvenv')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}